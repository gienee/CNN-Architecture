{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rh8QtiiZRL5E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.datasets import cifar100\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "6YvA1BqIRY3G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "nb_epochs = 10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "#Pre-process the data\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SqG_qxWRgld",
        "outputId": "dc09eefa-7b2f-437d-d3a2-279367fa1dc1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 9s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "V0bfNnlqUORw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(resnet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBt8-pgPUWkR",
        "outputId": "c0a6c687-6af4-4cfe-d0bc-6b7b215255cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Compile the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AzCfOKAcUeEq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "#checkpoint = ModelCheckpoint(filepath='mymodel.h5',\n",
        "#                               verbose=1, save_best_only=True)\n",
        "\"\"\"t=time.time()\n",
        "#x_train.shape[0] // 64\n",
        "historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=1),\n",
        "                                  steps_per_epoch=1,\n",
        "                                  epochs=1,\n",
        "                                  validation_data=(x_test, y_test))\n",
        "print('Training time: %s' % (t - time.time()))\"\"\""
      ],
      "metadata": {
        "id": "LlWrV6c3uriT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}